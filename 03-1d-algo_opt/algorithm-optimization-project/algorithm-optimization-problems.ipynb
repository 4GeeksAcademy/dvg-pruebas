{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b09e13",
   "metadata": {},
   "source": [
    "# Algorithm Optimization problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05e9bf",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Suppose a manager gives a task to two of his employees to design an algorithm in Python that efficiently compute sums of diagonals of a matrix.\n",
    "\n",
    "For example:\n",
    "\n",
    "```py\n",
    "Input : \n",
    "\n",
    "\n",
    "1 2 3 4\n",
    "4 3 2 1\n",
    "7 8 9 6\n",
    "6 5 4 3\n",
    "\n",
    "Output :\n",
    "\n",
    "Principal Diagonal: 16\n",
    "Secondary Diagonal: 20\n",
    "```\n",
    "\n",
    "The primary diagonal is formed by the elements 1,3,9,3. \n",
    " \n",
    "\n",
    "Condition for Principal Diagonal: The row-column condition is row = column. \n",
    "\n",
    "The secondary diagonal is formed by the elements 4,2,8,6.\n",
    "\n",
    "Condition for Secondary Diagonal: The row-column condition is row = number Of Rows – column -1.\n",
    "\n",
    "The algorithm developed by the first employee looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18cb2f",
   "metadata": {},
   "source": [
    "**Method 1:**\n",
    "\n",
    "In this method, he used two loops. A loop for columns and a loop for rows and in the inner loop we check for the condition stated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c592f03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Diagonal: 18\n",
      "Secondary Diagonal: 18\n"
     ]
    }
   ],
   "source": [
    "# A simple Python program to find sum of diagonals\n",
    "\n",
    "MAX = 100\n",
    " \n",
    "def DiagonalSums_emp1(mat, n):\n",
    " \n",
    "    principal = 0\n",
    "    secondary = 0;\n",
    "    for i in range(0, n):\n",
    "        for j in range(0, n):\n",
    " \n",
    "            # Condition for principal diagonal\n",
    "            if (i == j):\n",
    "                principal += mat[i][j]\n",
    " \n",
    "            # Condition for secondary diagonal\n",
    "            if ((i + j) == (n - 1)):\n",
    "                secondary += mat[i][j]\n",
    "                \n",
    "    print(\"Principal Diagonal:\", principal)\n",
    "    print(\"Secondary Diagonal:\", secondary)\n",
    " \n",
    "\n",
    "a = [[ 1, 2, 3, 4 ],\n",
    "     [ 5, 6, 7, 8 ],\n",
    "     [ 1, 2, 3, 4 ],\n",
    "     [ 5, 6, 7, 8 ]]\n",
    "\n",
    "DiagonalSums_emp1(a, 4)\n",
    " \n",
    "# This code is contributed\n",
    "# by ihritik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0567be",
   "metadata": {},
   "source": [
    "The algorithm developed by the second employee looks like this:\n",
    "\n",
    "**Method 2:**\n",
    "\n",
    "In this method we use one loop. A loop for calculating sum of both the principal and secondary diagonals: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca5e0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Diagonal: 18\n",
      "Secondary Diagonal: 18\n"
     ]
    }
   ],
   "source": [
    "# A simple Python3 program to find sum of diagonals\n",
    "MAX = 100\n",
    " \n",
    "def DiagonalSums_emp2(mat, n):\n",
    " \n",
    "    principal = 0\n",
    "    secondary = 0\n",
    "    for i in range(0, n):\n",
    "        principal += mat[i][i]\n",
    "        secondary += mat[i][n - i - 1]\n",
    "         \n",
    "    print(\"Principal Diagonal:\", principal)\n",
    "    print(\"Secondary Diagonal:\", secondary)\n",
    " \n",
    "\n",
    "a = [[ 1, 2, 3, 4 ],\n",
    "     [ 5, 6, 7, 8 ],\n",
    "     [ 1, 2, 3, 4 ],\n",
    "     [ 5, 6, 7, 8 ]]\n",
    "\n",
    "DiagonalSums_emp2(a, 4)\n",
    " \n",
    "# This code is contributed\n",
    "# by ihritik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd2b33",
   "metadata": {},
   "source": [
    "\n",
    "The manager has to decide which algorithm to use. To do so, he has to find the complexity of the algorithm. A good algorithm doesn't only find an answer, it finds it quickly and efficiently. But how do we evaluate how fast an algorithm is? One way to do so is by finding the time required to execute the algorithms. We can measure\n",
    "\n",
    "The %time command times a single run of a function. Here is an example on how it is used:\n",
    "\n",
    "```py\n",
    "In [3]: %time sum(range(100000))\n",
    "CPU times: user 2.68 ms, sys: 3 µs, total: 2.68 ms\n",
    "Wall time: 2.69 ms\n",
    "Out[3]: 4999950000\n",
    "```\n",
    "\n",
    "We can also use the time library:\n",
    "\n",
    "```py\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "# your code\n",
    "# end\n",
    "print(f'Time: {time.time() - start}')\n",
    "```\n",
    "\n",
    "Find the time required to execute each of the algorithms and make a conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929cef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE TO FIND THE TIME REQUIRED TO EXECUTE ALGORITHM BUILT BY THE FIRST EMPLOYEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8185a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE TO FIND THE TIME REQUIRED TO EXECUTE ALGORITHM BUILT BY THE SECOND EMPLOYEE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bad41",
   "metadata": {},
   "source": [
    "However, execution time is not a good metric to measure the complexity of an algorithm since it depends upon the hardware. A more objective complexity analysis metrics for the algorithms is needed. This is where Big O notation comes to play.\n",
    "\n",
    "As we already know, the complexity of an algorithm is said to :\n",
    "\n",
    "Constant if:\n",
    "\n",
    "The steps required to complete the execution of an algorithm remain constant, irrespective of the number of inputs. The constant complexity is denoted by O(c) where c can be any constant number.\n",
    "\n",
    "Linear if:\n",
    "\n",
    "The steps required to complete the execution of an algorithm increase or decrease linearly with the number of inputs. Linear complexity is denoted by O(n). For instance, if there are 4 inputs in the inputs list, the for-loop will be executed 4 times, and so on.\n",
    "\n",
    "Quadratic if:\n",
    "\n",
    "The steps required to execute an algorithm are a quadratic function of the number of items in the input. Quadratic complexity is denoted as O(n^2). The total number of steps performed is n * n, where n is the number of items in the input array.\n",
    "\n",
    "Find out the complexity of each algorithm in Big O Notation and draw a line plot with the varying size of the items input on the x-axis and the number of steps on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE TO MAKE A PLOT FOR THE FIRST EMPLOYEE'S SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2975d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE TO MAKE A PLOT FOR THE SECOND EMPLOYEE'S SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425bc2b8",
   "metadata": {},
   "source": [
    "## Exercise 2 : QuickSort algorithm\n",
    "\n",
    "Quicksort is a naturally recursive algorithm - divide the input array into smaller arrays, move the elements to the proper side of the pivot, and repeat. \n",
    "\n",
    "When we first call the algorithm, we consider all of the elements - from indexes **0** to **n-1** where **n** is the number of elements in our array. If our pivot ended up in position **k**, we'd then repeat the process for elements from **0 to k-1** and from **k+1** to **n-1**.\n",
    "\n",
    "This time we are going to order an array by using two functions - partition() and quick_sort(). The quick_sort() function will first partition() the collection and then recursively call itself on the divided parts.\n",
    "\n",
    "The code for the partition() function has been provided to you in the following cell. Use this partition() function to implement the quick_sort() function in order to sort the following array:\n",
    "\n",
    "array = [29,99,23,41,66,28,44,78,87,19,31,76,58,88,82,97,12,21,44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32eceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(array, start, end):\n",
    "    pivot = array[start]\n",
    "    low = start + 1\n",
    "    high = end\n",
    "\n",
    "    while True:\n",
    "        # If the current value we're looking at is larger than the pivot\n",
    "        # it's in the right place (right side of pivot) and we can move left,\n",
    "        # to the next element.\n",
    "        # We also need to make sure we haven't surpassed the low pointer, since that\n",
    "        # indicates we have already moved all the elements to their correct side of the pivot\n",
    "        while low <= high and array[high] >= pivot:\n",
    "            high = high - 1\n",
    "\n",
    "        # Opposite process of the one above\n",
    "        while low <= high and array[low] <= pivot:\n",
    "            low = low + 1\n",
    "\n",
    "        # We either found a value for both high and low that is out of order\n",
    "        # or low is higher than high, in which case we exit the loop\n",
    "        if low <= high:\n",
    "            array[low], array[high] = array[high], array[low]\n",
    "            # The loop continues\n",
    "        else:\n",
    "            # We exit out of the loop\n",
    "            break\n",
    "\n",
    "    array[start], array[high] = array[high], array[start]\n",
    "\n",
    "    return high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c22449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def quick_sort(array, start, end): (uncomment this line)\n",
    "    #COMPLETE HERE THE CODE OF THE quick_sort() ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN YOUR quick_sort() FUNCTION ON THE GIVEN ARRAY AND PRINT THE RESULT (SORTED ARRAY)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6a105",
   "metadata": {},
   "source": [
    "## Exercise 3: Implementing a KNN Algorithm with Scikit-learn\n",
    "\n",
    "In this exercise, we will have a brief introduction to the Scikit-learn library. We will see how this library can be used to implement the KNN algorithm in less than 20 lines of code.  Then the task will be to try to optimize the parameter of this algorithm. Don't worry! Scikit-Learn, and also de KNN algorithm will be explained very well in future modules.\n",
    "\n",
    "**The dataset**\n",
    "\n",
    "We are going to use the famous iris data set for our KNN example. The dataset consists of four attributes: sepal-width, sepal-length, petal-width and petal-length. These are the attributes of specific types of iris plant. The goal is to predict the class to which these plants belong. There are three classes in the dataset: Iris-setosa, Iris-versicolor and Iris-virginica.\n",
    "\n",
    "\n",
    "**Library installation**\n",
    "\n",
    "\n",
    "First let's install the Scikit-learn library by entering the following command in the terminal:\n",
    "\n",
    "```py\n",
    "pip install -U scikit-learn\n",
    "```\n",
    "\n",
    "Now let's see how to implement the KNN algorithm:\n",
    "\n",
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f17f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e87b86",
   "metadata": {},
   "source": [
    "**Importing and loading the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "# Assign colum names to the dataset\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "\n",
    "# Read dataset to pandas dataframe\n",
    "dataset = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd366f8",
   "metadata": {},
   "source": [
    "**Looking at the first rows of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dae7c8",
   "metadata": {},
   "source": [
    "**Pre-processing**\n",
    "\n",
    "Split dataset into attributes and labels. Again, don't worry, this data preprocessing part will also be very well explained in a future module. Now, we will focus on the algorithm optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b9dbed",
   "metadata": {},
   "source": [
    "**Train Test split**\n",
    "\n",
    "In machine learning, when we are building a model, we have to be careful to do not overfit it. Overfitting means that our model works very well in known data but when it works with unseen data, it has a poor performance. To avoid this, we divide our dataset into training and test datasets. This way our algorithm is tested on un-seen data to evaluate the performance of our algorithm. We will divide it into 80% training data and 20% for testing. This 4 blocks of data would be:\n",
    "\n",
    "-X_train: training features\n",
    "\n",
    "-X_test: test features\n",
    "\n",
    "-y_train: training labels\n",
    "\n",
    "-y_test: test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccaf14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b18743",
   "metadata": {},
   "source": [
    "**Feature Scaling**\n",
    "\n",
    "The majority of classifiers calculate the distance between two points by the Euclidean distance. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.\n",
    "\n",
    "It is a good practice to scale the features so that all of them can be uniformly evaluated.\n",
    "We will read more about feature scaling in the data preprocessing module, but now, let's have a first look at how it is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9904f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c368418",
   "metadata": {},
   "source": [
    "**Train the KNN algorithm**\n",
    "\n",
    "Now our data is ready for training. We will begin by importing the algorithm we want to train from the scikit-learn library, and then we will initialize it with one parameter: n_neigbours. This is basically the value for 'K'. We don't know what is the ideal number of neighbors(K) yet so we will start it with 5. After making the predictions we will try to otpimize this K value.\n",
    "\n",
    "Finally, we train our model using .fit on our training features and training labels (they both represent 80% of the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6cda99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b37ff9",
   "metadata": {},
   "source": [
    "**Make predictions on our test data**\n",
    "\n",
    "The model has been trained, so now we use the same algorithm (stored in the 'classifier' variable)  to predict only on the features of the test dataset (20% of the data). This time we don't use the labels, because we want to predict them, and then compare them with the real test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebcc483",
   "metadata": {},
   "source": [
    "**Evaluate the algorithm**\n",
    "\n",
    "Confusion matrix, precision, recall and f1 score are the most commonly used evaluation metrics for classification problems.\n",
    "The confusion_matrix and classification_report methods of the sklearn.metrics can be used to calculate these metrics. Here we will compare our y_pred results versus our y_test true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaac127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0365c265",
   "metadata": {},
   "source": [
    "**Optimizing the KNN algorithm**\n",
    "\n",
    "There is no way to know beforehand which value of 'K' yields the best results since the beginning. We randomly chose 5 as the 'K' value.\n",
    "\n",
    "This is where we apply our some python code to optimize our algorithm. To help find the best value of K:\n",
    "\n",
    "1. First create a function that calculates the mean of error for all the predicted values where K ranges from 1 to 40. \n",
    "2. Plot the error values against K values.\n",
    "3. Vary the test and training size along with the K value to see how your results differ and how can you improve the accuracy of your algorithm. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6418e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty error list.\n",
    "\n",
    "\n",
    "\n",
    "# Execute a loop from 1 to 40. In each iteration calculate the mean error for predicted values of test set\n",
    "\n",
    "#for i in range(1, 40): (uncomment this line)\n",
    "    #initialize the KNN algorithm\n",
    "   \n",
    "    #fit the train data\n",
    "    \n",
    "    #make predictions\n",
    "    \n",
    "    #append the result to the error list.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the error values against K values. Establish the graph size.\n",
    "\n",
    "# your code\n",
    "\n",
    "# title and labels (uncomment the following code lines)\n",
    "#plt.title('Error Rate K Value')\n",
    "#plt.xlabel('K Value')\n",
    "#plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b281af6e",
   "metadata": {},
   "source": [
    "Source:\n",
    "\n",
    "https://www.geeksforgeeks.org/\n",
    "\n",
    "https://stackabuse.com/big-o-notation-and-algorithm-analysis-with-python-examples/\n",
    "\n",
    "https://stackabuse.com/quicksort-in-python/\n",
    "\n",
    "https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9248718ffe6ce6938b217e69dbcc175ea21f4c6b28a317e96c05334edae734bb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
