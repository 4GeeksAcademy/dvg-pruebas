{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with the Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter can be used as a data source for various data science projects, including Geo-spatial analysis (where are users tweeting about certain subjects?) and sentiment analysis (how do users feel about certain subjects?).\n",
    "\n",
    "In this exercise we will learn how to stream real-time Twitter data. We will practice storing it in a dataframe to get some visualizations, as well as storing the data in a SQLite database, and building a web-app using Streamlit. Let's enumerate the tasks needed by dividing it into 3 areas:\n",
    "\n",
    "1. Database set-up: This can be done directly in the RDBMS of your choice, however we choose to use SQLite in this example.\n",
    "\n",
    "2. Tweepy: Credentials are required to interact with the Tweepy API. Once these have been obtained from dev.twitter.com we can set up a stream with keyword filters.\n",
    "\n",
    "3. Streamlit: Once we have our data stream working, we’ll need to set up our web app using Streamlit. This is surprisingly simple and can be done within a single python file!\n",
    "\n",
    "### Authentication\n",
    "\n",
    "Tweepy is a Python library to access the Twitter API. You’ll need to set up a twitter application at dev.twitter.com to attain a set of authentication keys to use with the API. Streaming with Tweepy comprises of three objects; Stream, StreamListener, OAuthHandler. The latter simply handles API authentication and requires the unique keys from the creation of your Twitter app. As Tweepy has been recently updated, and in order to avoid version conflicts, the streamlistener code will be provided to work with version ... of Tweepy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import tweepy,json\n",
    "\n",
    "# Store OAuth authentication credentials in relevant variables\n",
    "\n",
    "access_token = ACCESS_TOKEN\n",
    "access_token_secret = ACCESS_TOKEN_SECRET\n",
    "consumer_key = CONSUMER_KEY\n",
    "consumer_secret = CONSUMER_SECRET\n",
    "\n",
    "# Pass OAuth details to tweepy's OAuth handler\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stream import TweetListener\n",
    "\n",
    "# Initialize Stream listener\n",
    "l = TweetListener()\n",
    "\n",
    "# Create your Stream object with authentication\n",
    "stream = tweepy.Stream(auth, l)\n",
    "\n",
    "# Filter Twitter Streams to capture data by the keywords:\n",
    "stream.filter(['russia', 'ukraine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stream import TweetListener\n",
    "\n",
    "# Initialize Stream listener\n",
    "l = TweetListener()\n",
    "\n",
    "# Create your Stream object with authentication\n",
    "stream = tweepy.Stream(auth, l)\n",
    "\n",
    "# Filter Twitter Streams to capture data by the keywords:\n",
    "stream.filter(['russia', 'ukraine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a dataframe with our Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Build DataFrame of tweet texts and languages\n",
    "df = pd.DataFrame(tweets_data, columns=['text', 'lang'])\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizing some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store tweet counts\n",
    "[russia, ukraine] = [0, 0, 0, 0]\n",
    "\n",
    "# Iterate through df, counting the number of tweets in which\n",
    "# each candidate is mentioned\n",
    "for index, row in df.iterrows():\n",
    "    russia += word_in_text('russia', row['text'])\n",
    "    ukraine += word_in_text('ukraine', row['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# Create a list of labels:cd\n",
    "cd = ['russia', 'ukraine']\n",
    "\n",
    "# Plot the bar chart\n",
    "ax = sns.barplot(cd, [russia, ukraine])\n",
    "ax.set(ylabel=\"count\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
